<!DOCTYPE html>
<html lang="en" class="h-100">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Tennessee RobUst, Secure, and Trustworthy AI Seminar">
    <meta name="keywords" content="TRUST-AI, Seminar ">
    <link rel="icon" type="image/png" href="http://localhost:4000/favicon.png">
    <link rel="stylesheet" href="/assets/lib/bootstrap.min.css" type="text/css">
    <link rel="stylesheet" href="/assets/css/styles.css">
    <title>Fall 2024 | TRUST-AI</title>
  </head>

  <body class="d-flex flex-column h-100">
    <div id="skip-to-content"><a href="#maincontent">Skip to main content</a></div>
    
    <!-- Header (Navbar) -->
    <header>
      <nav class="navbar navbar-expand-lg navbar-light bg-light pb-lg-0 border-bottom">
        <style>
          .navbar-brand-custom {
              font-size: 1.5rem;
              font-weight: bold;
          }
          .nav-link-custom {
              font-size: 1.2rem;
          }
        </style>
        <div class="container">
          <a class="navbar-brand navbar-brand-custom" href="/">
            <img src="/images/trustai.png" alt="Trust AI" style="height: 100px; margin-right: 10px; border-radius: 50%;">
            TRUST-AI
          </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#mainNav" aria-controls="mainNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>

          <div class="collapse navbar-collapse justify-content-end" id="mainNav">
            <ul class="navbar-nav nav-tabs justify-content-end">
              <li class="nav-item">
                <a class="nav-link nav-link-custom p-3 h-100" href="2024fall.html">Fall 2024</a>
              </li>
              <li class="nav-item">
                <a class="nav-link nav-link-custom p-3 h-100" href="2025spring.html">Spring 2025</a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>


    <!-- Main Content for Fall 2024 -->

    <hr>
    <main id="maincontent" role="main" aria-label="Content" class="flex-shrink-0">

      <div class="container" style="max-width: 800px; margin: 0 auto;"> <!-- Set max-width for alignment -->

          
        <div style="text-align: center;">
          <div class="speaker">
            <a href="https://mi-zhang.github.io/" target="_blank">
              <img src="/images/24fall/mi.jpeg" alt="Mi Zhang" style="border-radius: 50%; width: 150px; height: 150px;" />
            </a>
            <p><strong><a href="https://mi-zhang.github.io/" target="_blank" class="speaker-link">Mi Zhang</a></strong><br />The Ohio State University</p>
          </div>
          
          <p><strong>Time: </strong> Friday, Oct. 18 12:30 PM - 1:30 PM &nbsp;&nbsp;&nbsp;&nbsp;<strong> Location:</strong> MKB 622</p>  
          <p><strong>Building Efficient, Scalable, and Heterogeneous Federated Learning Systems</strong></p>
        </div>

        <div style="max-width: 800px; margin: 0 auto; text-align: justify;">
          <p><strong>Abstract:</strong></p>  
          <p> Data privacy has become a critical concern in modern AI systems. As a remedy to this concern, federated learning (FL) has emerged as a privacy-preserving machine learning paradigm where clients distributed at different geographical locations can collaboratively train an AI model while keeping their own data locally. While theoretical studies in federated learning have made significant progress, we are still confronted with challenges on building practical federated learning systems. 
            In this talk, I will share our experiences in building efficient, scalable, and heterogeneous federated learning systems. First, I will present our work on developing an importance-sampling based FL framework that significantly enhances the training efficiency under the limited wireless network bandwidth without compromising the training quality. Second, I will focus on the client selection component of the FL pipeline and talk about our work on developing a data and system heterogeneity-aware client selection scheme that jointly enhances the efficiency and scalability of FL systems. Third, we present a simple yet powerful framework that enables model-heterogeneous FL, where models with different capacities can be trained on end systems with heterogeneous resources. This work lays the foundation for developing FL systems for training large-scale AI models such as large language models and foundation models in general. I will conclude the talk by briefly introducing our recent initiative on FedAIoT whose vision is to extend FL to much richer data modalities and compute devices encountered in the real world.
            </p>

          <p><strong>Bio:</strong></p>  
          <p>Mi Zhang is an Associate Professor and the Director of AIoT and Machine Learning Systems Lab at The Ohio State University (OSU). He received his Ph.D. in Computer Engineering and M.S. in both Electrical Engineering and Computer Science from University of Southern California and B.S. in Electrical Engineering from Peking University. Before joining OSU, he was a tenured Associate Professor at Michigan State University and a postdoctoral scholar at Cornell University. His research lies at the intersection of systems and machine intelligence, spanning areas including edge AI, efficient AI, federated learning, multimodal large language models and generative AI, systems for machine learning, and human-centered AI for health and social good. Dr. Zhang has received a number of awards for his work. He is the 4th Place Winner (1st Place in U.S. and Canada) of 2019 Google MicroNet Challenge (CIFAR-100 Track), the Third Place Winner of 2017 NSF Hearables Challenge, and the champion of 2016 NIH Pill Image Recognition Challenge. He is the recipient of eight best paper awards and nominations. He is also the recipient of NSF CRII Award, Facebook Faculty Research Award, Amazon Machine Learning Research Award, MSU Innovation of the Year Award, and the inaugural USC ECE SIPI Distinguished Alumni Award in the Junior/Academia category. </p>
         </div>
      </div>

    
    <hr>
    <main id="maincontent" role="main" aria-label="Content" class="flex-shrink-0">

      <div class="container" style="max-width: 800px; margin: 0 auto;"> <!-- Set max-width for alignment -->

          
        <div style="text-align: center;">
          <div class="speaker">
            <a href="https://people.duke.edu/~zg70/" target="_blank">
              <img src="/images/24fall/gong.jpeg" alt="Neil Gong" style="border-radius: 50%; width: 150px; height: 150px;" />
            </a>
            <p><strong><a href="https://people.duke.edu/~zg70/" target="_blank" class="speaker-link">Neil Gong</a></strong><br />Duke University</p>
          </div>
          
          <p><strong>Time: </strong> Friday, Oct. 4 12:30 PM - 1:30 PM &nbsp;&nbsp;&nbsp;&nbsp;<strong> Location:</strong> MKB 622</p>  
          <p><strong>Secure Content Moderation for Generative AI</strong></p>
        </div>

        <div style="max-width: 800px; margin: 0 auto; text-align: justify;">
          <p><strong>Abstract:</strong></p>  
          <p>Generative AI–such as GPT-4 and DALL-E 3–raises many ethical and legal concerns such as the generation of harmful content, scaling disinformation and misinformation campaigns, as well as disrupting education and learning. Content moderation for generative AI aims to address these ethical and legal concerns via 1) preventing a generative AI model from synthesizing harmful content, and 2) detecting AI-generated content. Prevention is often implemented using safety filters, while detection is implemented by watermark. Both prevention and watermark-based detection have been recently widely deployed by industry. In this talk, we will discuss the security of existing prevention and watermark-based detection methods in adversarial settings.</p>

          <p><strong>Bio:</strong></p>  
          <p>Neil Gong is an Associate Professor in the Department of Electrical and Computer Engineering and Department of Computer Science (secondary appointment) at Duke University. His research interests are cybersecurity and privacy with a recent focus on AI security. He received an NSF CAREER Award, Army Research Office Young Investigator Program (YIP) Award, Rising Star Award from the Association of Chinese Scholars in Computing, IBM Faculty Award, Facebook Research Award, and multiple best paper or best paper honorable mention awards. He received a B.E. from the University of Science and Technology of China in 2010 (with the highest honor) and a Ph.D in Computer Science from the University of California Berkeley in 2015.</p>
          <!-- <p>Dr. Murat Kantarcioglu is a Professor and CCI Faculty Fellow at the Virginia Tech Department of Computer Science. Before he joined Virginia Tech, he was an Asbhel Smith Professor of Computer Science at UT Dallas. He earned his PhD in Computer Science from Purdue University in 2005, where he was awarded the Purdue CERIAS Diamond Award for Academic Excellence. He also holds affiliations as a Faculty Associate at Harvard's Data Privacy Lab and as a Visiting Scholar at UC Berkeley's RISE Labs. Dr. Kantarcioglu's research centers on integrating cybersecurity, data science, and blockchain technologies to develop secure and efficient data processing and sharing mechanisms. His research has been supported by numerous grants from agencies such as NSF, AFOSR, ARO, ONR, NSA, and NIH. Dr. Kantarcioglu has authored over 180 peer-reviewed papers in top-tier venues including NDSS, CCS, USENIX Security, KDD, SIGMOD, ICDM, ICDE, PVLDB, and several IEEE/ACM Transactions. He has also served as Program Co-Chair for prestigious conferences such as IEEE ICDE, ACM SACMAT, IEEE Cloud, IEEE CNS, and ACM CODASPY. His research has been featured by media outlets such as the Boston Globe, ABC News, PBS/KERA, and DFW Television, and he has received multiple best paper awards. Dr. Kantarcioglu is the recipient of several notable awards, including the NSF CAREER Award, the AMIA 2014 Homer R. Warner Award, and the IEEE ISI 2017 Technical Achievement Award, jointly presented by the IEEE SMC and IEEE ITS societies, for his contributions to data security and privacy. He is also a Fellow of both the AAAS and IEEE.</p> -->
        </div>
      </div>


      <hr>
        <div class="container" style="max-width: 800px; margin: 0 auto;"> <!-- Set max-width for alignment -->

          
          <div style="text-align: center;">
            <div class="speaker">
              <a href="https://www.kantarcioglu.net/" target="_blank">
                <img src="/images/24fall/murat.jpeg" alt="Murat Kantarcioglu" style="border-radius: 50%; width: 150px; height: 150px;" />
              </a>
              <p><strong><a href="https://www.kantarcioglu.net/" target="_blank" class="speaker-link">Murat Kantarcioglu</a></strong><br />Virginia Tech</p>
            </div>
            
            <p><strong>Time: </strong> Friday, Sep. 20 12:30 PM - 1:30 PM &nbsp;&nbsp;&nbsp;&nbsp;<strong> Location:</strong> MKB 622</p>  
            <p><strong>Defending and Defeating AI: Protecting the Good, Attacking the Bad for Privacy, Security and Fairness</strong></p>
          </div>
  
          <div style="max-width: 800px; margin: 0 auto; text-align: justify;">
            <p><strong>Abstract:</strong></p>  
            <p>AI models are increasingly being deployed for a wide range of critical tasks, from healthcare diagnosis to autonomous driving. However, recent research has revealed that these models are vulnerable to various attacks, including data poisoning and test-time evasion, which can severely compromise their effectiveness. In this talk, we will begin by exploring some of our current work aimed at enhancing the robustness of AI models by reducing the transferability of attacks and developing novel defense techniques in the context of Federated Learning. Additionally, we will discuss how blockchain-based incentive mechanisms can be employed to further mitigate potential attacks by fostering a more secure environment for AI deployment. Finally, we will discuss whether explainable AI based approaches could be used to rectify some of the AI errors. In the second part of the talk, we will shift focus to the offensive side, presenting our work on attacking AI models that may violate privacy or fairness. These proactive attacks are designed to expose and rectify flaws in AI systems, ensuring they are used in a way that protects individual privacy and promotes fairness.</p>
  
            <p><strong>Bio:</strong></p>  
            <p>Dr. Murat Kantarcioglu is a Professor and CCI Faculty Fellow at the Virginia Tech Department of Computer Science. Before he joined Virginia Tech, he was an Asbhel Smith Professor of Computer Science at UT Dallas. He earned his PhD in Computer Science from Purdue University in 2005, where he was awarded the Purdue CERIAS Diamond Award for Academic Excellence. He also holds affiliations as a Faculty Associate at Harvard's Data Privacy Lab and as a Visiting Scholar at UC Berkeley's RISE Labs. Dr. Kantarcioglu's research centers on integrating cybersecurity, data science, and blockchain technologies to develop secure and efficient data processing and sharing mechanisms. His research has been supported by numerous grants from agencies such as NSF, AFOSR, ARO, ONR, NSA, and NIH. Dr. Kantarcioglu has authored over 180 peer-reviewed papers in top-tier venues including NDSS, CCS, USENIX Security, KDD, SIGMOD, ICDM, ICDE, PVLDB, and several IEEE/ACM Transactions. He has also served as Program Co-Chair for prestigious conferences such as IEEE ICDE, ACM SACMAT, IEEE Cloud, IEEE CNS, and ACM CODASPY. His research has been featured by media outlets such as the Boston Globe, ABC News, PBS/KERA, and DFW Television, and he has received multiple best paper awards. Dr. Kantarcioglu is the recipient of several notable awards, including the NSF CAREER Award, the AMIA 2014 Homer R. Warner Award, and the IEEE ISI 2017 Technical Achievement Award, jointly presented by the IEEE SMC and IEEE ITS societies, for his contributions to data security and privacy. He is also a Fellow of both the AAAS and IEEE.</p>
          </div>
        </div>
      </main>
    <!-- Footer -->
    <footer class="site-footer bg-light mt-auto">
      <div class="container" style="padding: 0px;">
        <div class="row align-items-center pb-2">
          <div style="flex: 1; padding: 5px; text-align: center;">
            <div style="width: 40%; margin: auto;"> <!-- Reduced width -->
              <img src="./images/utk.webp" style="width: 100%; border-radius: 50%;"> <!-- Reduced border-radius -->
            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Bootstrap JS bundle -->
    <script src="/assets/lib/bootstrap.bundle.min.js"></script>

    <script>
      // Scroll-to-top button
      window.onscroll = function () {
        if (document.body.scrollTop > 500 || document.documentElement.scrollTop > 500) {
          document.getElementById("scroll-to-top").style.display = "block";
        } else {
          document.getElementById("scroll-to-top").style.display = "none";
        }
      }
      function scrollToTop() {
        window.scroll({
          top: 0, 
          left: 0, 
          behavior: 'smooth'
        });
      }
    </script>

    <button id="scroll-to-top" type="button" class="btn btn-link btn-lg" onclick="scrollToTop();" title="Back to Top" aria-label="Back to Top">
      <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-up-square" viewBox="0 0 16 16">
        <path fill-rule="evenodd" d="M15 2a1 1 0 0 0-1-1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2zM0 2a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v12a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V2zm8.5 9.5a.5.5 0 0 1-1 0V5.707L5.354 7.854a.5.5 0 1 1-.708-.708l3-3a.5.5 0 0 1 .708 0l3 3a.5.5 0 0 1-.708.708L8.5 5.707V11.5z"/>
      </svg>
    </button>
  </body>
</html>
