<!DOCTYPE html>
<html lang="en" class="h-100">
  <head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<!-- <title>TRUST-AI</title> -->
<meta name="description" content="Tennessee RobUst, Secure, and Trustworthy AI Seminar">
<meta name="keywords" content="TRUST-AI, Seminar ">
<meta name="author" content="">
<link rel="icon" type="image/png" href="http://localhost:4000/favicon.png">

<!--
  _      __         __        __           ______               __     __     
 | | /| / /__  ____/ /__ ___ / /  ___  ___/_  __/__ __ _  ___  / /__ _/ /____ 
 | |/ |/ / _ \/ __/  '_/(_-</ _ \/ _ \/ _ \/ / / -_)  ' \/ _ \/ / _ `/ __/ -_)
 |__/|__/\___/_/ /_/\_\/___/_//_/\___/ .__/_/  \__/_/_/_/ .__/_/\_,_/\__/\__/ 
                                    /_/                /_/                    

    built with workshop-template-b, evanwill, https://github.com/evanwill/workshop-template-b
--> 
   
<!-- Open Graph meta -->
<meta property="og:title" content="TRUST-AI" />
<meta property="og:type" content="website" />
<meta property="og:description" content="Tennessee RobUst, Secure, and Trustworthy AI Seminar" />
<meta property="og:image" content="http://localhost:4000/images/trustai.png" />
<meta property="og:site_name" content="TRUST-AI" />
<meta property="og:url" content="http://localhost:4000/content/25spring.html" />
<meta property="og:locale" content="en_US" />
<!-- schema.org JSON-LD -->
<script type="application/ld+json">{ "@context":"http://schema.org", "@type":"WebPage", "headline":"TRUST-AI", "author": { "@type":"Person", "name":""}, "description":"Tennessee RobUst, Secure, and Trustworthy AI Seminar", "image": "http://localhost:4000/images/trustai.png", "url":"http://localhost:4000/content/25spring.html" }</script>


<link rel="stylesheet" href="/assets/lib/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="/assets/css/styles.css">


<!-- Last build date: 2024-09-15 -->
  </head>

  <body class="d-flex flex-column h-100">
    <div id="skip-to-content"><a href="#maincontent">Skip to main content</a></div>
    <header>
    <nav class="navbar navbar-expand-lg navbar-light bg-light pb-lg-0 border-bottom">
    <style>
        .navbar-brand-custom {
            font-size: 1.5rem; /* Adjust this value as needed */
            font-weight: bold; /* Optional: to make the text bold */
        }

        .nav-link-custom {
            font-size: 1.2rem; /* Adjust this value as needed */
        }
    </style>
    <div class="container">
        <a class="navbar-brand navbar-brand-custom" href="/">
            
            <img src="/images/trustai.png" alt="Trust AI" style="height: 100px; margin-right: 10px; border-radius: 50%;">
            TRUST-AI
        </a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#mainNav" aria-controls="mainNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse justify-content-end" id="mainNav">
            <ul class="navbar-nav nav-tabs justify-content-end">
            
                <li class="nav-item">
                    <a class="nav-link nav-link-custom p-3 h-100" href="2024fall.html">Fall 2024</a>
                </li>
            
                <!-- <li class="nav-item">
                    <a class="nav-link nav-link-custom p-3 h-100" href="/content/24fall.html">Fall 2024</a>
                </li> -->
            
                <li class="nav-item">
                    <a class="nav-link nav-link-custom active p-3 h-100" href="2025spring.html">Spring 2025</a>
                </li>
            
            </ul>  
        </div>
    </div>
</nav>

    </header>


    <hr>
    <main id="maincontent" role="main" aria-label="Content" class="flex-shrink-0">

      <div class="container" style="max-width: 800px; margin: 0 auto;"> <!-- Set max-width for alignment -->

          
        <div style="text-align: center;">
          <div class="speaker">
            <a href="https://ischool.utexas.edu/profiles/ken-fleischmann" target="_blank">
              <img src="/images/25spring/ken.jpg" alt="Kenneth Fleischmann" style="border-radius: 50%; width: 150px; height: 150px;" />
            </a>
            <p><strong><a href="https://ischool.utexas.edu/profiles/ken-fleischmann" target="_blank" class="speaker-link">Kenneth Fleischmann</a></strong><br />The University of Texas at Austin</p>
          </div>
          
          <p><strong>Time: </strong> Friday, May. 2 12:30 PM - 1:30 PM &nbsp;&nbsp;&nbsp;&nbsp;<strong> Location:</strong> Online</p>  
          <p><strong>Zoom Link: </strong><a href="https://tennessee.zoom.us/j/85451157513"><strong>https://tennessee.zoom.us/j/85451157513</strong></a></p>

          <p><strong> Smart Hand Tools: Trustworthy AI for Skilled Trade Workers</strong></p>
        </div>

        <div style="max-width: 800px; margin: 0 auto; text-align: justify;">
          <p><strong>Abstract:</strong></p>  
          <p>The public release of ChatGPT in 2022 has drawn attention to the role of AI in the future of knowledge work, but what are the implications of AI for the future of skilled trade work? 
            <a href="https://bridgingbarriers.utexas.edu/good-systems/projects/making-smart-tools-work-for-everyone" target="_blank"><strong>The Smart Hand Tools project</strong></a>, a core research project of <a href="https://bridgingbarriers.utexas.edu/good-systems" target="_blank"><strong>Good Systems: Ethical AI at UT Austin</strong></a>, seeks to leverage edge AI, sensors, and the internet of things to put the power of AI into workers’ hands. Through field research in collaboration with Austin Community College, the City of Austin, and Texas AFL-CIO, we have identified opportunities to improve skilled trade training and practice using smart hand tools. This user research informed our design, development, and deployment of prototype smart hand tools, including a smart rotary hand tool and an augmented reality welding simulator. The goals of smart hand tools are to leverage AI to empower skilled trade workers rather than threatening skilled trade workers’ jobs. A smart hand tool could provide guidance that could accelerate training and reduce the incidence of repetitive stress injuries and workplace accidents. It could also give workers control of data that they could use in situations such as filing a workers’ compensation claim or in collective bargaining. This talk will provide an overview of research to date and planned future research directions.</p>
          <p><strong>Bio:</strong></p>  
          <p>Dr. Kenneth R. Fleischmann is a Professor in the School of Information at UT Austin. He is also the Founding Chair of Good Systems: Ethical AI at UT Austin, the Founding Director of Undergraduate Studies for the iSchool's B.A./B.S. in Informatics, and the Founding Editor-in-Chief of the ACM Journal on Responsible Computing. For twenty-five years, his research and teaching have focused on the ethics of AI and more broadly on the role of human values in the design and use of information technologies. His research has been funded by the National Science Foundation (NSF), MITRE, IARPA, Microsoft Research, Cisco Research Center, Micron Foundation, and the Public Interest Technology University Network. His research has been recognized by iConference Best Paper awards in 2012, 2021, and 2022; the ASIS&T Best Information Behavior Conference Paper Award in 2012 and 2022; the ASIS&T SIG-SI Social Informatics Best Paper Award in 2018; the ASIS&T SIG-AI Artificial Intelligence Best Paper Award in 2023; the Civic Futures Award for Designing for the 100% in 2019; and the MetroLab Innovation of the Month Award in July 2020 and October 2021.</p>
          </div>
      </div>


    <hr>
    <main id="maincontent" role="main" aria-label="Content" class="flex-shrink-0">

      <div class="container" style="max-width: 800px; margin: 0 auto;"> <!-- Set max-width for alignment -->

          
        <div style="text-align: center;">
          <div class="speaker">
            <a href="https://pronskikh.org/" target="_blank">
              <img src="./images/25spring/vitaly.jpeg" alt="Vitaly Pronskikh" style="border-radius: 50%; width: 150px; height: 150px;" />
            </a>
            <p><strong><a href="https://pronskikh.org/" target="_blank" class="speaker-link">Vitaly Pronskikh</a></strong><br />Oak Ridge National Laboratory</p>
          </div>
          
          <p><strong>Time: </strong> Friday, Apr. 11 12:30 PM - 1:30 PM &nbsp;&nbsp;&nbsp;&nbsp;<strong> Location:</strong> MKB 622</p>  
          
          <p><strong>Beyond the Algorithm: Trustworthy AI as Shared Responsibility</strong></p>
        </div>

        <div style="max-width: 800px; margin: 0 auto; text-align: justify;">
          <p><strong>Abstract:</strong></p>  
          <p>
            As artificial intelligence (AI) becomes increasingly embedded in high-stakes domains like nuclear reactor control and radiation protection, questions of trust and accountability grow more pressing. Conventional approaches tend to equate trust with technical performance—accuracy, reliability, explainability—but in critical applications, this narrow view falls short. In this talk, I argue that AI trustworthiness must be re-conceptualized as a form of shared moral responsibility, emerging not from machine autonomy but from accountable entanglement across the human and institutional actors who shape AI systems. Drawing from responsibility philosophy, actor-network theory, and the theory-ladenness of observation, I show how AI systems are never neutral tools: they are built on layered models, situated assumptions, and evolving narratives, from design and simulation to deployment and public communication. Through case studies in radiation protection, nuclear medicine, and autonomous control in nuclear operations, I explore how theoretical assumptions, data annotations, and validation strategies become morally significant—especially when simulation infrastructures blur the boundary between empirical evidence and constructed behavior. I show that AI trustworthiness is not an intrinsic feature of the system, but emerges from how responsibility is distributed, institutionalized, and sustained within the broader sociotechnical context in which the system operates.
          </p>
          <p><strong>Bio:</strong></p>  
          <p>
            Vitaly Pronskikh is a Neutronics Scientist at the Second Target Station of Oak Ridge National Laboratory (ORNL) and an Associate Member of the Center for Philosophy of Science at the University of Pittsburgh. He joined ORNL in 2023 after holding research appointments at Fermi National Accelerator Laboratory since 2010. His work spans nuclear and particle physics, radiation protection, and advanced computer simulations—fields that increasingly intersect with

            AI and questions of scientific methodology. Dr. Pronskikh’s interests include the epistemological and ethical dimensions of simulation-based science, as well as the historical and philosophical contexts in which scientific technologies evolve. He holds doctoral degrees in both Nuclear and Particle Physics and Philosophy of Science and Technology. He is a finalist in the 2024 Smoky Mountains Computational Sciences & Engineering Conference (SMCDC) Essay Contest on Trustworthy AI for Science.
          </p>
           </div>
      </div>



    <hr>
    <main id="maincontent" role="main" aria-label="Content" class="flex-shrink-0">

      <div class="container" style="max-width: 800px; margin: 0 auto;"> <!-- Set max-width for alignment -->

          
        <div style="text-align: center;">
          <div class="speaker">
            <a href="https://www.cs.cornell.edu/~shmat/" target="_blank">
              <img src="./images/25spring/vitaly.jpg" alt="Vitaly Shmatikov" style="border-radius: 50%; width: 150px; height: 150px;" />
            </a>
            <p><strong><a href="https://www.cs.cornell.edu/~shmat/" target="_blank" class="speaker-link">Vitaly Shmatikov</a></strong><br />Cornell University</p>
          </div>
          
          <p><strong>Time: </strong> Friday, Apr. 4 12:30 PM - 1:30 PM &nbsp;&nbsp;&nbsp;&nbsp;<strong> Location:</strong> MKB 622</p>  
          
          <p><strong>What You See Is Not What You Get: Multi-Modal AI Systems Are Not Secure</strong></p>
        </div>

        <div style="max-width: 800px; margin: 0 auto; text-align: justify;">
          <p><strong>Abstract:</strong></p>  
          <p>Modern AI/ML systems (in particular, semantic retrieval and LLM-based systems) accept not just text inputs but also images, audio, video, and other modalities.  In this talk, I will show how attackers can exploit non-text vectors for spamming, misinformation, malicious code execution, and other adversarial objectives.  I will also discuss why adversarial robustness seems difficult to achieve in multi-modal systems.</p>
          <p><strong>Bio:</strong></p>  
          <p>Vitaly Shmatikov is a Professor of Computer Science at Cornell University and Cornell Tech.  Research by Dr. Shmatikov, his students, and collaborators received the Caspar Bowden PET Award for Outstanding Research in Privacy Enhancing Technologies three times; Test-of-Time Awards from the IEEE Symposium on Security and Privacy (S&P / “Oakland”), ACM Conference on Computer and Communications Security (CCS), and the ACM/IEEE Symposium on Logic in Computer Science (LICS); as well as several outstanding and distinguished paper awards, most recently from USENIX Security 2021 and 2024 and EMNLP 2023.

          </p>
           </div>
      </div>


    <!-- Main Content for Spring 2025 -->

    <hr>
    <main id="maincontent" role="main" aria-label="Content" class="flex-shrink-0">

      <div class="container" style="max-width: 800px; margin: 0 auto;"> <!-- Set max-width for alignment -->

          
        <div style="text-align: center;">
          <div class="speaker">
            <a href="https://linkedin.com/in/charlie-epperson" target="_blank">
              <img src="/images/25spring/charlie.jpeg" alt="Charlie Epperson" style="border-radius: 50%; width: 150px; height: 150px;" />
            </a>
            <p><strong><a href="https://linkedin.com/in/charlie-epperson" target="_blank" class="speaker-link">Charlie Epperson</a></strong><br />U.S. Coast Guard</p>
          </div>
          
          <p><strong>Time: </strong> Friday, Mar. 7 12:30 PM - 1:30 PM &nbsp;&nbsp;&nbsp;&nbsp;<strong> Location:</strong> MKB 622</p>  
          <!-- <p><strong>Zoom Link: </strong><a href="https://tennessee.zoom.us/j/84778963050"><strong>https://tennessee.zoom.us/j/84778963050</strong></a></p> -->

          <p><strong> Bridging the Gap: AI R&D and Real-World Maritime Intelligence Application</strong></p>
        </div>

        <div style="max-width: 800px; margin: 0 auto; text-align: justify;">
          <p><strong>Abstract:</strong></p>  
          <p>The intersection of maritime intelligence and artificial intelligence presents transformative opportunities for enhancing maritime domain awareness. This presentation explores how the Coast Guard and partners have pursued AI capabilities, including computer vision, generative AI, and autonomous systems, to address critical maritime challenges such as counter-narcotics, migration, and search and rescue. CDR Epperson will detail ongoing interagency initiatives focused on developing organic AI capabilities and integrating cutting-edge commercial solutions. Furthermore, he will outline key engagement pathways for university AI researchers to contribute to the U.S. Government's AI efforts.</p>
          <p><strong>Bio:</strong></p>  
          <p>Commander Charlie Epperson serves as the Deputy Chief of Artificial Intelligence within the U.S. Coast Guard's Office of Intelligence, where he leads efforts to integrate advanced AI technologies into maritime operations. Prior to this role, he was the Acting Director of Humanitarian Assistance and Disaster Relief (HADR) at the Department of Defense's Joint Artificial Intelligence Center (JAIC), spearheading initiatives to modernize disaster response through AI, including wildfire mitigation, rapid damage assessment, and enhanced search and rescue.

            With 22 years of operational experience, CDR Epperson has served in diverse and challenging environments, including a five-year assignment in Guam focusing on search and rescue, and deployments with the National Strike Force responding to the BP Deepwater Horizon oil spill and major hurricane response operations.
            
            CDR Epperson holds a Master of Public Administration (MPA) from the Lee Kuan Yew School of Public Policy at the National University of Singapore, a graduate certificate in Community Preparedness & Disaster Management (CPDM) from the University of North Carolina and completed the National Preparedness Leadership Initiative at Harvard University. He is a proud alumnus and Letterman of the University of Tennessee. Outside of his professional life, CDR Epperson and his wife are avid long-distance runners and dedicated Tennessee baseball fans.</p>
          </div>
      </div>

      
    <main id="maincontent" role="main" aria-label="Content" class="flex-shrink-0">
      
      <div class="container my-4">
<h1></h1>

<div class="ms-5 mb-3 border-bottom">
    </div>
    
<div class="my-4">

<!-- <p>All seminars are at 12:30 PM on Fridays. Please see below for speakers, dates and locations. For those unable to attend in person, recordings will be shared on our <a href="https://www.youtube.com/channel/UCaZx8BUCa2M_orwYAuXacRg">YouTube channel</a>.</p> -->


</div>

</div>
      
    </main>

    <footer class="site-footer bg-light mt-auto">
  <div class="container" style="padding: 0px 0;">
    <!-- <nav class="mt-2 mb-3"> 
      <ul class="nav nav-pills nav-fill">
        
        <li class="nav-item"><a class="nav-link h3" href="/124fall.html">Fall 2024</a></li>
        
        <li class="nav-item"><a class="nav-link h3" href="/content/24fall.html">Fall 2024</a></li>
        
        <li class="nav-item"><a class="nav-link h3 active" href="/content/25spring.html">Spring 2025</a></li>
        
      </ul>
    </nav> -->
    <!-- <div class="row align-items-center pb-2"> 
        <div id="footer-title" class="col-md">
         
          <br>
         </div>
        <div class="col-md">
          
          <script>
            function site_search() {
              var query = document.getElementById("site-search").value;
              window.open("/search/index.html?q=" + encodeURIComponent(query), "_self" );
            }
          </script>
          <form class="form-inline my-2 my-lg-0 float-end" role="search" id="search" onsubmit="site_search(); return false;">
            <div class="input-group">
              <input id="site-search" class="form-control form-control-sm" type="text" placeholder="Search" aria-label="Search box"> 
              <button class="btn btn-secondary btn-sm" type="submit"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-search" viewBox="0 0 16 16"> <path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"/> </svg><span class="visually-hidden">submit search</span></button> </div>
          </form>
          
        </div>
    </div> -->
    <div class="row align-items-center pb-2"> <!-- Reduced padding-bottom -->
      <div style="flex: 1; padding: 5px; text-align: center;"> <!-- Reduced padding -->
        <div style="width: 40%; margin: auto;"> <!-- Reduced width -->
          <img src="./images/utk.webp" style="width: 100%; border-radius: 50%;"> <!-- Reduced border-radius -->
        </div>
      </div>
    </div>
  </div>
</footer>

    <!-- Bootstrap JS bundle -->
<script src="/assets/lib/bootstrap.bundle.min.js"></script>
<!-- load other optional js -->



<script>
    // When the user scrolls down from the top of the document, show the button
    window.onscroll = function () {
        if (document.body.scrollTop > 500 || document.documentElement.scrollTop > 500) {
            document.getElementById("scroll-to-top").style.display = "block";
        } else {
            document.getElementById("scroll-to-top").style.display = "none";
        }
    }
    // scroll to top function
    function scrollToTop() {
        window.scroll({
            top: 0, 
            left: 0, 
            behavior: 'smooth'
        });
    }
</script>
<button id="scroll-to-top" type="button" class="btn btn-link btn-lg" onclick="scrollToTop();" title="Back to Top" aria-label="Back to Top">
    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-up-square" viewBox="0 0 16 16"> <path fill-rule="evenodd" d="M15 2a1 1 0 0 0-1-1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2zM0 2a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v12a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V2zm8.5 9.5a.5.5 0 0 1-1 0V5.707L5.354 7.854a.5.5 0 1 1-.708-.708l3-3a.5.5 0 0 1 .708 0l3 3a.5.5 0 0 1-.708.708L8.5 5.707V11.5z"/> </svg>
</button>



  </body>

</html>