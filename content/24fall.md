---
# title: Introduction
nav: Fall 2024
---

<!-- <hr> -->


<hr>





<div style="text-align: center;">
    <div class="speaker">
        <a href="https://www.kantarcioglu.net/" target="_blank">
            <img src="../images/24fall/murat.jpeg" alt="Murat Kantarcioglu" style="border-radius: 50%; width: 150px; height: 150px;">
        </a>
        <p><strong><a href="https://www.kantarcioglu.net/" target="_blank" class="speaker-link">Murat Kantarcioglu</a></strong><br>Virginia Tech</p>
    </div>
    
    <p><strong>Time: </strong> Friday, Sep. 20 12:30 PM - 1:30 PM &nbsp;&nbsp;&nbsp;&nbsp;<strong> Location:</strong> MKB 622</p>  
    <p><strong>Defending and Defeating AI: Protecting the Good, Attacking the Bad for Privacy, Security and Fairness</strong></p>

    <div style="max-width: 800px; margin: 0 auto; text-align: justify;">
        <p><strong>Abstract:</strong></p>  
        <p>AI models are increasingly being deployed for a wide range of critical tasks, from healthcare diagnosis to autonomous driving. However, recent research has revealed that these models are vulnerable to various attacks, including data poisoning and test-time evasion, which can severely compromise their effectiveness. In this talk, we will begin by exploring some of our current work aimed at enhancing the robustness of AI models by reducing the transferability of attacks and developing novel defense techniques in the context of Federated Learning. Additionally, we will discuss how blockchain-based incentive mechanisms can be employed to further mitigate potential attacks by fostering a more secure environment for AI deployment. Finally, we will discuss whether explainable AI based approaches could be used to rectify some of the AI errors. In the second part of the talk, we will shift focus to the offensive side, presenting our work on attacking AI models that may violate privacy or fairness. These proactive attacks are designed to expose and rectify flaws in AI systems, ensuring they are used in a way that protects individual privacy and promotes fairness.</p>

        <p><strong>Bio:</strong></p>  
        <p>Dr. Murat Kantarcioglu is a Professor and CCI Faculty Fellow at the Virginia Tech Department of Computer Science. Before he joined Virginia Tech, he was an Asbhel Smith Professor of Computer Science at UT Dallas. He earned his PhD in Computer Science from Purdue University in 2005, where he was awarded the Purdue CERIAS Diamond Award for Academic Excellence. He also holds affiliations as a Faculty Associate at Harvard's Data Privacy Lab and as a Visiting Scholar at UC Berkeley's RISE Labs. Dr. Kantarcioglu's research centers on integrating cybersecurity, data science, and blockchain technologies to develop secure and efficient data processing and sharing mechanisms. His research has been supported by numerous grants from agencies such as NSF, AFOSR, ARO, ONR, NSA, and NIH. Dr. Kantarcioglu has authored over 180 peer-reviewed papers in top-tier venues including NDSS, CCS, USENIX Security, KDD, SIGMOD, ICDM, ICDE, PVLDB, and several IEEE/ACM Transactions. He has also served as Program Co-Chair for prestigious conferences such as IEEE ICDE, ACM SACMAT, IEEE Cloud, IEEE CNS, and ACM CODASPY. His research has been featured by media outlets such as the Boston Globe, ABC News, PBS/KERA, and DFW Television, and he has received multiple best paper awards. Dr. Kantarcioglu is the recipient of several notable awards, including the NSF CAREER Award, the AMIA 2014 Homer R. Warner Award, and the IEEE ISI 2017 Technical Achievement Award, jointly presented by the IEEE SMC and IEEE ITS societies, for his contributions to data security and privacy. He is also a Fellow of both the AAAS and IEEE.</p>
    </div>
</div>
